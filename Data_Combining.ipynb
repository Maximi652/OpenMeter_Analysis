{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542a5fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c39489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messdaten = pd.read_csv(\"AlleMessdaten2000_2024.csv\")\n",
    "df_wetterdaten = pd.read_csv(\"Wetterdaten.csv\")\n",
    "df_ferien = pd.read_csv(\"ferientage_2000_2025.csv\")\n",
    "\n",
    "df_feiertage = pd.read_excel(\"DeutscheFeiertage.xlsx\", \n",
    "                             dtype={\"Feiertag\": \"category\", \n",
    "                                    \"Datum\": \"object\", \n",
    "                                    \"Bundesland\": \"category\"})\n",
    "\n",
    "df_feiertage[\"Datum\"] = pd.to_datetime(df_feiertage[\"Datum\"]).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af3285",
   "metadata": {},
   "source": [
    "Einige Datensätze hatten keine Zuordnung zu einem Bundesland\n",
    "\n",
    "array(['Frechen', 'Köln', 'Monheim', 'Bergisch Gladbach', 'Berlin',\n",
    "       'Bonn', 'Leverkusen', 'Langenfeld', 'Düsseldorf', nan],\n",
    "      dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afea3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messdaten.loc[\n",
    "    (df_messdaten[\"federal_state\"] == \"Sonstige\") & (df_messdaten[\"city\"].isin(['Frechen', 'Köln', 'Monheim', 'Bergisch Gladbach', 'Bonn', 'Leverkusen', 'Langenfeld', 'Düsseldorf'])), \n",
    "    \"federal_state\"\n",
    "    ] = \"Nordrhein-Westfalen\"\n",
    "\n",
    "df_messdaten.loc[\n",
    "    (df_messdaten[\"federal_state\"] == \"Sonstige\") & (df_messdaten[\"city\"] == \"Berlin\"), \n",
    "    \"federal_state\"\n",
    "    ] = \"Berlin\"\n",
    "\n",
    "# Es gibt eine Verbrauchsstelle ohne Bundesland, Ort oder PLZ\n",
    "# Annahme: NRW\n",
    "df_messdaten.loc[\n",
    "    df_messdaten[\"federal_state\"].isna(), \n",
    "    \"federal_state\"\n",
    "    ] = \"Nordrhein-Westfalen\"\n",
    "\n",
    "# Es gibt eine Verbrauchsstelle ohne Bundesland und Ort, aber mit PLZ\n",
    "df_messdaten.loc[df_messdaten[\"federal_state\"] == \"Sonstige\", \"federal_state\"] = \"Nordrhein-Westfalen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25ea4fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             date            state  count\n",
      "1       2000-01-01 00:00:00+00:00           Bayern      7\n",
      "2       2000-01-01 00:00:00+00:00           Berlin      4\n",
      "3       2000-01-01 00:00:00+00:00      Brandenburg      9\n",
      "4       2000-01-01 00:00:00+00:00           Bremen      9\n",
      "5       2000-01-01 00:00:00+00:00          Hamburg      9\n",
      "...                           ...              ...    ...\n",
      "117804  2024-12-31 00:00:00+00:00  Rheinland-Pfalz      5\n",
      "117805  2024-12-31 00:00:00+00:00         Saarland      9\n",
      "117806  2024-12-31 00:00:00+00:00          Sachsen      5\n",
      "117807  2024-12-31 00:00:00+00:00   Sachsen-Anhalt      5\n",
      "117808  2024-12-31 00:00:00+00:00        Thüringen      8\n",
      "\n",
      "[117371 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Prüfung, ob Wetterdaten von mehreren Stationen im gleichen Bundesland pro Tag vorliegen\n",
    "# Wie viele Duplikate gibt es pro (date, state) in den Wetterdaten?\n",
    "dups = df_wetterdaten.groupby(['date', 'state']).size().reset_index(name='count')\n",
    "dups = dups[dups['count'] > 1]\n",
    "print(dups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f0b20",
   "metadata": {},
   "source": [
    "Zusammenführen der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd690f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sicherstellen, dass die Datumsformate übereinstimmen\n",
    "df_messdaten['Zeitstempel'] = pd.to_datetime(df_messdaten['Zeitstempel']).dt.date\n",
    "df_wetterdaten['date'] = pd.to_datetime(df_wetterdaten['date']).dt.date\n",
    "\n",
    "agg_dict = {\n",
    "    'station_id': 'first',\n",
    "    'resolution': 'first',\n",
    "    'dataset': 'first',\n",
    "    'parameter': 'first',\n",
    "    'value': 'mean',        # numerisch\n",
    "    'quality': 'min',\n",
    "    'name': 'first'\n",
    "}\n",
    "\n",
    "# Wetterdaten vorher pivotisieren, da sonst Duplikate nach dem Join im DataFrame auftreten\n",
    "df_wetter_pivot = df_wetterdaten.pivot_table(\n",
    "    index=['date', 'state'],\n",
    "    columns='parameter',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ").reset_index()\n",
    "\n",
    "# Klimadaten mergen anhand Datum und Bundesland\n",
    "df = pd.merge(\n",
    "    df_messdaten,\n",
    "    df_wetter_pivot,\n",
    "    left_on=['Zeitstempel', 'federal_state'],\n",
    "    right_on=['date', 'state'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# doppelte Zeit- und Ortsangaben entfernen\n",
    "df.drop(columns=['date', 'state'], inplace=True)\n",
    "\n",
    "# nur die Messwerte beibehalten, die auch Klimainformationen haben\n",
    "df = df.loc[df[\"temperature_air_mean_2m\"].isna() == False]\n",
    "\n",
    "# Wochentag\n",
    "df[\"Wochentag\"] = pd.to_datetime(df[\"Zeitstempel\"]).apply(lambda x: datetime.date.isoweekday(x))\n",
    "\n",
    "# in Bezeichnung umschlüsseln\n",
    "dict_weekday = {1: \"Montag\",\n",
    "                2: \"Dienstag\",\n",
    "                3: \"Mittwoch\",\n",
    "                4: \"Donnerstag\",\n",
    "                5: \"Freitag\",\n",
    "                6: \"Samstag\",\n",
    "                7: \"Sonntag\"}\n",
    "\n",
    "df[\"Wochentag_Name\"] = df[\"Wochentag\"].apply(lambda x: dict_weekday.get(x))\n",
    "\n",
    "# Feiertage mergen\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_feiertage,\n",
    "    left_on=['Zeitstempel', 'federal_state'],\n",
    "    right_on=['Datum', 'Bundesland'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df.drop(columns=['Datum', 'Bundesland'], inplace=True)\n",
    "\n",
    "# selbes Datumformat zum mergen, hier gab es vorher Probleme ohne Konvertierung des Datums\n",
    "df[\"Zeitstempel\"] = pd.to_datetime(df[\"Zeitstempel\"])\n",
    "df_ferien[\"Datum\"] = pd.to_datetime(df_ferien[\"Datum\"])\n",
    "\n",
    "# Ferien mergen\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_ferien,\n",
    "    left_on=[\"Zeitstempel\", \"federal_state\"],\n",
    "    right_on=[\"Datum\", \"Bundesland\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df.drop(columns=[\"Datum\", \"Bundesland\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "676d0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"EnrichedSensorData.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
